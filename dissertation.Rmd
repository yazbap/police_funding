---
title: "Dissertation Analysis"
output: html_document
date: "2024-04-11"
---

<style type="text/css">
.main-container {
  max-width: 1800px;
  margin-left: auto;
  margin-right: auto;
}
</style>


```{r set_up, include = FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

# read in the libraries
library(tidyverse) 
library(scales)
library(haven)
library(readxl)
library(gridExtra)
library(MatchIt)
library(missForest)
library(knitr)
library(ggplot2)
library(moments)
library(patchwork)
library(tmap)
library(sf)
library(tigris)
library(haven)
library(mice)
library(scales)

```

```{r functions}
# Function to standardize data types based on the first data frame
standardize_data_types <- function(df, first_df) {
  for (col_name in names(first_df)) {
    col_type <- typeof(first_df[[col_name]])
    if (col_type == "integer" || col_type == "numeric") {
      df[[col_name]] <- as.numeric(df[[col_name]])
    } else if (col_type == "character") {
      df[[col_name]] <- as.character(df[[col_name]])
    } else if (col_type == "logical") {
      df[[col_name]] <- as.logical(df[[col_name]])
    }
    # Add conditions for other data types if necessary
  }
  return(df)
}

transform_skewed_data <- function(data) {
  before_skewness <- c()  # Vector to store skewness values before transformation
  
  for (col in colnames(data)) {
    before_skewness <- c(before_skewness, moments::skewness(data[[col]]))  # Record skewness before transformation
    
    skewness_value <- moments::skewness(data[[col]])
    
    if (skewness_value > 1) {
      # Log transform for high positive skewness
      data[[col]] <- log(data[[col]] + 1)  # Adding 1 to avoid log(0)
    } else if (skewness_value < -1) {
      # Square root transform for high negative skewness
      data[[col]] <- sqrt(max(data[[col]] + 1) - data[[col]])
    } else if (skewness_value > 0.5) {
      # Square root transform for moderate positive skewness
      data[[col]] <- sqrt(data[[col]])
    } else if (skewness_value < -0.7) {
      # Square transform for moderate negative skewness
      data[[col]] <- (max(data[[col]]) - data[[col]])^2
    }
    
    if (col == "median_hh_income"){
      min_val <- min(data[[col]], na.rm = TRUE)
      max_val <- max(data[[col]], na.rm = TRUE)
      data[[col]] <- (data[[col]] - min_val) / (max_val - min_val)
    }
    
  }
  
  after_skewness <- sapply(data, moments::skewness)  # Calculate skewness after transformation
  
  # Create a data frame to display skewness values before and after transformation
  skewness_table <- data.frame(
    Variable = colnames(data),
    Before_Transformation = before_skewness,
    After_Transformation = after_skewness
  )
  
  return(data)
}

process_demo_data <- function(df, place_col) {
  df %>%
    rename(
      total_pop = AV0AA225,
      num_female = AV1AB225,
      age_under_5 = B57AA225,
      age_5_9 = B57AB225,
      age_10_14 = B57AC225,
      age_15_17 = B57AD225,
      age_18_19 = B57AE225,
      age_20 = B57AF225,
      age_21 = B57AG225,
      age_22_24 = B57AH225,
      age_25_29 = B57AI225,
      age_30_34 = B57AJ225,
      age_35_44 = B57AK225,
      age_45_54 = B57AL225,
      age_55_59 = B57AM225,
      age_60_61 = B57AN225,
      age_62_64 = B57AO225,
      age_65_74 = B57AP225,
      age_75_84 = B57AQ225,
      age_85_up = B57AR225,
      num_black = B07AB225,
      num_white = B07AA225,
      num_asian = B07AD225,
      num_hispanic = A35AA225,
      num_less_hs = B85AA225,
      num_hs_graduate_GED = B85AC225,
      num_associates = B85AE225,
      num_bachelors = B85AF225,
      num_graduate_professional = B85AG225,
      num_not_in_labor_force = B84AF225,
      median_hh_income = B79AA225
    ) %>%
    mutate(
      percent_female = num_female / total_pop,
      perc_age_0_17 = (age_under_5 + age_5_9 + age_10_14 + age_15_17) / total_pop,
      perc_age_18_34 = (age_18_19 + age_20 + age_21 + age_22_24 + age_25_29 + age_30_34) / total_pop,
      perc_age_35_59 = (age_35_44 + age_45_54 + age_55_59) / total_pop,
      perc_age_60_74 = (age_60_61 + age_62_64 + age_65_74) / total_pop,
      perc_75_up = (age_75_84 + age_85_up) / total_pop,
      perc_black = num_black / total_pop,
      perc_asian = num_asian / total_pop,
      perc_white = num_white / total_pop,
      perc_hispanic = num_hispanic / total_pop,
      perc_less_hs = num_less_hs / total_pop,
      perc_associates = num_associates / total_pop,
      perc_bachelors = num_bachelors / total_pop,
      perc_graduate_professional = num_graduate_professional / total_pop,
      perc_not_in_labor_force = num_not_in_labor_force / total_pop,
      state_abbr = state.abb[match(STATE, state.name)],
      PLACE = tolower(gsub(" County| Borough| Census Area| Municipality| Parish| city| town| CDP| village| City", "", !!sym(place_col))), # Remove suffixes
      city_state = paste(PLACE, state_abbr, sep = "_") # Combine place and state
    ) %>%
    select(
      city_state, percent_female, perc_age_0_17, perc_age_18_34, perc_age_35_59,
      perc_age_60_74, perc_75_up, perc_black, perc_asian, perc_white, perc_hispanic,
      perc_less_hs, perc_associates, perc_bachelors, perc_graduate_professional,
      perc_not_in_labor_force, median_hh_income
    )
}

prepare_and_save_diff_in_diff <- function(df, protest_type, pre_col, post_col, output_file) {
  outcome_vars_pre <- df %>%
    select(agency_name, !!sym(pre_col), !!sym(protest_type)) %>%
    mutate(time = 0) %>%  # Pre-treatment period indicator
    rename(opbudget = !!sym(pre_col))
  
  outcome_vars_post <- df %>%
    select(agency_name, !!sym(post_col), !!sym(protest_type)) %>%
    mutate(time = 1) %>%
    rename(opbudget = !!sym(post_col))
  
  diff_in_diff_df <- bind_rows(outcome_vars_pre, outcome_vars_post)
  
  # Create the formula for the model
  formula <- reformulate(c(paste(protest_type, "* time")), response = "opbudget")
  
  diff_diff_output <- lm(formula, data = diff_in_diff_df)
  diff_summary <- summary(diff_diff_output)
  
  table <- data.frame(
    Variable = rownames(diff_summary$coefficients),
    Estimate = diff_summary$coefficients[, "Estimate"],
    Std_Error = diff_summary$coefficients[, "Std. Error"],
    t_value = diff_summary$coefficients[, "t value"],
    P_Value = diff_summary$coefficients[, "Pr(>|t|)"]
  )
  
  return(table)
}

create_pscores <- function(df, protest_var, drop_var){
  filtered_df <- df %>% select(-!!sym(drop_var))
  
  # Logistic regression to calculate propensity scores
  pscores_model <- glm(as.formula(paste(protest_var, "~ mrp_ideology + percent_female + perc_age_0_17 + perc_age_18_34 + perc_age_35_59 + perc_age_60_74 + perc_75_up + perc_black + perc_white + perc_hispanic + perc_less_hs + perc_associates + perc_bachelors + perc_graduate_professional + perc_not_in_labor_force + median_hh_income + has_police_killing + is_city + opbudget2013 + opbudget2016")), 
    data = filtered_df, 
    family = binomial(link = "logit")
  )
  
  # Add propensity scores to the data frame
  filtered_df$p_score <- predict(pscores_model, newdata = filtered_df, type = "response")
  
  return(filtered_df)
}

process_and_plot <- function(df, removed_rows, remove_col, plot_title, output_file) {
  # Add a column indicating if the row was removed in the original dataset
  df <- df %>% mutate(removed_status = ifelse(rownames(df) %in% removed_rows, "Removed", "Not Removed"))

  # List of continuous and binary variables to visualize
  continuous_vars <- c("mrp_ideology", "percent_female", "perc_age_0_17", "perc_age_18_34",
                       "perc_age_35_59", "perc_age_60_74", "perc_75_up", "perc_black",
                       "perc_white", "perc_hispanic", "perc_less_hs", "perc_associates",
                       "perc_bachelors", "perc_graduate_professional", "perc_not_in_labor_force",
                       "median_hh_income")
  binary_vars <- c("has_police_killing")

  # Calculate the means for continuous variables and convert to long format
  continuous_means <- df %>%
    group_by(removed_status) %>%
    summarise(across(all_of(continuous_vars), mean, na.rm = TRUE)) %>%
    pivot_longer(cols = -removed_status, names_to = "variable", values_to = "mean")

  # Calculate the means for binary variables and convert to long format
  binary_means <- df %>%
    group_by(removed_status) %>%
    summarise(across(all_of(binary_vars), mean, na.rm = TRUE)) %>%
    pivot_longer(cols = -removed_status, names_to = "variable", values_to = "mean") %>%
    mutate(variable = paste(variable, "(binary)"))

  # Combine both continuous and binary variables
  combined_means <- bind_rows(continuous_means, binary_means)

  # Plot combined means
  plot <- ggplot(combined_means, aes(x = mean, y = variable, fill = removed_status)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Mean", y = "Variable", fill = "Removed Status", title = plot_title) +
    scale_fill_manual(values = c("Removed" = "red", "Not Removed" = "darkgrey")) +
    theme_minimal() +
    theme(axis.text.y = element_text(size = 10), axis.title.y = element_blank())

  return(plot)
}

# Define a function to initialize the result table
initialize_result_table <- function() {
  data.frame(
    Variable = character(),
    Control_Mean = numeric(),
    Treatment_Mean = numeric(),
    Control_SD = numeric(),
    Treatment_SD = numeric(),
    Control_Percentage = numeric(),
    Treatment_Percentage = numeric(),
    stringsAsFactors = FALSE
  )
}

# Define a function to process each variable and create a new row for the result table
process_variable <- function(variable, group, data) {
  variable_names <- c(
    "mrp_ideology" = "Ideology",
    "percent_female" = "Percent Female",
    "perc_age_0_17" = "Percent Age 0-17",
    "perc_age_18_34" = "Percent Age 18-34",
    "perc_age_35_59" = "Percent Age 35-59",
    "perc_age_60_74" = "Percent Age 60-74",
    "perc_75_up" = "Percent Age 75+",
    "perc_black" = "Percent Black",
    "perc_white" = "Percent White",
    "perc_hispanic" = "Percent Hispanic",
    "perc_less_hs" = "Percent Less Than High School",
    "perc_associates" = "Percent Associates",
    "perc_bachelors" = "Percent Bachelors",
    "perc_graduate_professional" = "Percent Graduate/Professional",
    "perc_not_in_labor_force" = "Percent Not in Labor Force",
    "median_hh_income" = "Median Household Income",
    "has_police_killing" = "Has Police Killing"
  )
  
  if (variable == "has_police_killing") {
    # For binary variables, calculate proportions
    prop_treatment <- mean(data[[variable]][data[[group]] == 1], na.rm = TRUE)
    prop_control <- mean(data[[variable]][data[[group]] == 0], na.rm = TRUE)
    data.frame(
      Variable = variable_names[[variable]],
      Control_Mean = NA,
      Treatment_Mean = NA,
      Control_SD = NA,
      Treatment_SD = NA,
      Control_Percentage = as.numeric(prop_control),
      Treatment_Percentage = as.numeric(prop_treatment),
      stringsAsFactors = FALSE
    )
  } else {
    # Perform t-test and compute means and standard deviations for continuous variables
    mean_treatment <- mean(data[[variable]][data[[group]] == 1], na.rm = TRUE)
    mean_control <- mean(data[[variable]][data[[group]] == 0], na.rm = TRUE)
    sd_treatment <- sd(data[[variable]][data[[group]] == 1], na.rm = TRUE)
    sd_control <- sd(data[[variable]][data[[group]] == 0], na.rm = TRUE)
    data.frame(
      Variable = variable_names[[variable]],
      Control_Mean = as.numeric(mean_control),
      Treatment_Mean = as.numeric(mean_treatment),
      Control_SD = as.numeric(sd_control),
      Treatment_SD = as.numeric(sd_treatment),
      Control_Percentage = NA,
      Treatment_Percentage = NA,
      stringsAsFactors = FALSE
    )
  }
}

# Define a function to create the result table
create_result_table <- function(group, data) {
  variables <- c("mrp_ideology", "percent_female", "perc_age_0_17", "perc_age_18_34",
                 "perc_age_35_59", "perc_age_60_74", "perc_75_up", "perc_black",
                 "perc_white", "perc_hispanic", "perc_less_hs", "perc_associates",
                 "perc_bachelors", "perc_graduate_professional", "perc_not_in_labor_force",
                 "median_hh_income", "has_police_killing")
  
  result_table <- initialize_result_table()
  for (variable in variables) {
    new_row <- process_variable(variable, group, data)
    result_table <- bind_rows(result_table, new_row)
  }
  result_table %>%
    mutate(
      Control_Mean = format(Control_Mean, scientific = FALSE, digits = 4),
      Treatment_Mean = format(Treatment_Mean, scientific = FALSE, digits = 4),
      Control_SD = format(Control_SD, scientific = FALSE, digits = 4),
      Treatment_SD = format(Treatment_SD, scientific = FALSE, digits = 4)
    ) %>%
    rename(
      `Control Mean` = Control_Mean,
      `Treatment Mean` = Treatment_Mean,
      `Control Std Dev` = Control_SD,
      `Treatment Std Dev` = Treatment_SD,
      `Control Percentage` = Control_Percentage,
      `Treatment Percentage` = Treatment_Percentage
    )
}

calculate_rmse <- function(df1, df2) {
  # Ensure only numeric columns are considered
  numeric_cols <- sapply(df1, is.numeric)
  df1_numeric <- df1[, numeric_cols]
  df2_numeric <- df2[, numeric_cols]
  
  # Calculate RMSE
  sqrt(mean((as.matrix(df1_numeric) - as.matrix(df2_numeric))^2, na.rm = TRUE))
}

calculate_range <- function(df) {
  numeric_cols <- sapply(df, is.numeric)
  df_numeric <- df[, numeric_cols]
  
  # Calculate range for each numeric column
  range_values <- sapply(df_numeric, function(col) diff(range(col, na.rm = TRUE)))
  range_values[range_values == 0] <- 1 # Avoid division by zero
  
  mean(range_values)
}

compute_summary_stats <- function(data) {
  # Remove NA values
  clean_data <- na.omit(data)
  
  # Calculate statistics
  min_val <- min(clean_data, na.rm = TRUE)
  q1 <- quantile(clean_data, 0.25, na.rm = TRUE)
  median_val <- median(clean_data, na.rm = TRUE)
  mean_val <- mean(clean_data, na.rm = TRUE)
  q3 <- quantile(clean_data, 0.75, na.rm = TRUE)
  max_val <- max(clean_data, na.rm = TRUE)
  na_count <- sum(is.na(data))
  
  # Format statistics with commas
  formatted_stats <- c(
    "Min." = comma(min_val),
    "1st Qu." = comma(q1),
    "Median" = comma(median_val),
    "Mean" = comma(mean_val),
    "3rd Qu." = comma(q3),
    "Max." = comma(max_val)
  )
  
  return(formatted_stats)
}

run_parallel_trends <- function(data, protest_var, reference_year = "2019") {
  # Create individual data frames for each year
  budget_2013 <- data %>%
    select(agency_name, opbudget2013, !!sym(protest_var)) %>%
    mutate(year = 2013) %>%
    rename(opbudget = opbudget2013)
  
  budget_2016 <- data %>%
    select(agency_name, opbudget2016, !!sym(protest_var)) %>%
    mutate(year = 2016) %>%
    rename(opbudget = opbudget2016)
  
  budget_2019 <- data %>%
    select(agency_name, opbudget2019, !!sym(protest_var)) %>%
    mutate(year = 2019) %>%
    rename(opbudget = opbudget2019)
  
  budget_2020 <- data %>%
    select(agency_name, opbudget2020, !!sym(protest_var)) %>%
    mutate(year = 2020) %>%
    rename(opbudget = opbudget2020)
  
  budget_2021 <- data %>%
    select(agency_name, opbudget2021, !!sym(protest_var)) %>%
    mutate(year = 2021) %>%
    rename(opbudget = opbudget2021)
  
  # Combine all yearly data frames into one
  diff_in_diff_df <- bind_rows(budget_2013, budget_2016, budget_2019, budget_2020, budget_2021)
  
  # Set year as a factor and set the reference level
  diff_in_diff_df$year <- as.factor(diff_in_diff_df$year)
  diff_in_diff_df$year <- relevel(diff_in_diff_df$year, ref = reference_year)
  
  # Run the regression model
  model_formula <- as.formula(paste("opbudget ~", protest_var, "* factor(year)"))
  reg1 <- lm(model_formula, data = diff_in_diff_df)
  
  diff_summary <- summary(reg1)
  
  table <- data.frame(
    Variable = rownames(diff_summary$coefficients),
    Estimate = diff_summary$coefficients[, "Estimate"],
    Std_Error = diff_summary$coefficients[, "Std. Error"],
    t_value = diff_summary$coefficients[, "t value"],
    P_Value = diff_summary$coefficients[, "Pr(>|t|)"]
  )
  
  # Return the summary of the regression model
  return(table)
}
```

## Data Sources

- **2020 BLM protest Data**
  - Accessed from The Armed Conflict Location & Event Data Project (ACLED)
- **Demographic County Data**
  - Characteristics
    - Percent Female
    - Age 0-18, 19-35, 36-50, 50-65, 65+
    - Percent Black, Asian, White, Hispanic or Latino
    - Person's 25 and older educational attainment
    - Median HH income
  - Accessed from IPUMS National Historical Geographic Information System (NHGIS) from the 2022 American Community Survey (ACS) Summary Files which estimates average characteristics from 2018 to 2022. 
- **Ideology Data**
  - Values are between 0 and 1, lower values are associated with politically left preferences and higher values with politically right preferences
  - Ideology is based on surveys taken between 2017-2021
  - Accessed from the Harvard Dataverse, dataset: Subnational ideology and presidential vote estimates (v2022)
- **Police Killings Data**
  - Average Police Killings Per Capita from 2016 - 2020
  - Accessed from mapping Police Violence


```{r get_protest_data}
# Load protest data
raw <- read.csv("data/2020-01-01-2024-04-19-United_States.csv")

# Filter for BLM protests in 2020 and process the data
blm_df <- raw %>%
  filter(year == 2020, str_detect(tolower(assoc_actor_1), "blm")) %>%
  mutate(
    
    # Update 'admin2' for specific event IDs
    admin2 = ifelse(event_id_cnty %in% c("USA4796", "USA17359", "USA12192", 
                                         "USA9274", "USA9021", "USA8471", 
                                         "USA18357"), "new york", admin2),
    
    # Reclassify 'sub_event_type'
    sub_event_type = ifelse(sub_event_type %in% c("Violent demonstration", 
                                                  "Mob violence", 
                                                  "Protest with intervention", 
                                                  "Excessive force against protesters"),
                            "violent_protest", "peaceful_protest"),
    
    # Replace empty 'location' and 'admin2' with NA
    location = ifelse(location == "", NA, location),
    admin2 = ifelse(admin2 == "", NA, admin2),
    
    # Convert 'location', 'admin2', and 'admin1' to lowercase
    location = tolower(location),
    admin2 = tolower(admin2),
    admin1 = tolower(admin1),
    
    # Get state abbreviation from 'admin1'
    state_abbr = state.abb[match(admin1, tolower(state.name))],
    
    # Create 'city_state' and 'county_state'
    city_state = paste(location, state_abbr, sep = "_"),
    county_state = paste(admin2, state_abbr, sep = "_")
  )

# Summarise data for cities
cities_blm <- blm_df %>%
  group_by(city_state) %>%
  summarise(
    violent_protest = as.integer(any(sub_event_type == "violent_protest")),
    peaceful_protest = as.integer(all(sub_event_type == "peaceful_protest"))
  ) %>%
  mutate(is_city = 1) %>%
  rename(location = city_state)

# Summarise data for counties
counties_blm <- blm_df %>%
  group_by(county_state) %>%
  summarise(
    violent_protest = as.integer(any(sub_event_type == "violent_protest")),
    peaceful_protest = as.integer(all(sub_event_type == "peaceful_protest"))
  ) %>%
  mutate(is_city = 0) %>%
  rename(location = county_state)

# Combine cities and counties data
blm <- bind_rows(cities_blm, counties_blm)

```

```{r get_political_data}
# Load political ideology data for cities, counties, and zip codes
cities_pol_ideo <- read_dta("data/ideo/aip_cities_ideology_v2022a.dta")
counties_pol_ideo <- read_dta("data/ideo/aip_counties_ideology_v2022a.dta")
zips_pol_ideo <- read_dta("data/ideo/aip_zips_ideology_v2022a.dta")

# Process cities data
cities_pol_ideo <- cities_pol_ideo %>%
  
  # Only use data from the most recent surveys
  filter(survey_period == "2017-2021") %>%
  mutate(
    
    # Get state abbreviations
    state_abbr = state.abb[match(state, state.name)], 
    
    # Remove suffixes
    city_name = tolower(gsub(" County| Borough| Census Area| Municipality| Parish| city", "", city_name)),  

    # Combine city and state
    city_state = paste(city_name, state_abbr, sep = "_")
  ) %>%
  
  # Select relevant columns
  select(city_state, mrp_ideology)

# Process counties data
counties_pol_ideo <- counties_pol_ideo %>%
  
  # Only use data from the most recent surveys
  filter(survey_period == "2017-2021") %>%  
  mutate(
    
    # Get state abbreviations
    state_abbr = state.abb[match(state, state.name)], 
    
    # Remove suffixes
    county_name = tolower(gsub(" County| Borough| Census Area| Municipality| Parish| city", "", county_name)),
    county_state = paste(county_name, state_abbr, sep = "_")  # Combine county and state
  ) %>%
  
  # Select relevant columns
  select(county_state, mrp_ideology)

# Handle duplicate counties by averaging their ideology scores
counties_pol_ideo <- counties_pol_ideo %>%
  group_by(county_state) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  ungroup()

# Process zip code data by name
zips_pol_ideo_by_name <- zips_pol_ideo %>%
  mutate(
    zip_name = str_replace(zip_name, ", ", "_"),
    zip_name = str_replace(zip_name, "([^_]+)(_.*)", function(x) {
      paste0(str_to_lower(sub("_.*", "", x)), sub("^[^_]+", "", x))
    })
  ) %>%
  group_by(zip_name) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  ungroup() %>%
  select(zip_name, mrp_ideology) %>%
  rename(city_state = zip_name)

# Process zip code data by zip number
zips_pol_ideo_by_num <- zips_pol_ideo %>%
  group_by(zip) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  ungroup() %>%
  select(zip, mrp_ideology) %>%
  mutate(zip = as.character(zip))

```

```{r get_demographic_data}
# Load demographic data for cities and counties
cities_demo <- read.csv("data/demo/nhgis0006_ts_nominal_place.csv")
counties_demo <- read.csv("data/demo/nhgis0004_ts_nominal_county.csv")

# Process cities and counties data
cities_demo_df <- process_demo_data(cities_demo, "PLACE")
counties_demo_df <- process_demo_data(counties_demo, "COUNTY")

# Summarise cities data and add city indicator
cities_processed <- cities_demo_df %>%
  group_by(city_state) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(is_city = 1) %>%
  rename(location = city_state)

# Summarise counties data and add city indicator
counties_processed <- counties_demo_df %>%
  group_by(city_state) %>%
  summarise(across(everything(), mean, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(is_city = 0) %>%
  rename(location = city_state)

# Combine cities and counties data
demographics <- bind_rows(cities_processed, counties_processed)

```

```{r get_police_killings}
# Load police killings data
police_killings_df <- suppressWarnings(
  suppressMessages(
    read_excel("data/MPVDatasetDownload.xlsx", sheet = "2013-2024 Police Killings")
  )
)

# Process city-level police killings data
city_police_killings <- police_killings_df %>%
  filter(!is.na(City)) %>%  # Keep rows with non-missing City
  mutate(
    `Date of Incident (month/day/year)` = as.Date(`Date of Incident (month/day/year)`),  # Convert date to Date type
    year = year(`Date of Incident (month/day/year)`),  # Extract year
    City = tolower(gsub(" County| Borough| Census Area| Municipality| Parish| city", "", City)),  # Remove suffixes
    city_state = paste(tolower(City), State, sep = "_")  # Combine city and state
  ) %>%
  filter(year >= 2016 & year <= 2020) %>%  # Filter for years 2016-2020
  group_by(city_state) %>%  # Group by city_state
  dplyr::summarize(count = n(), .groups = 'drop') %>%  # Count incidents
  mutate(
    has_police_killing = ifelse(count > 0, 1, 0),  # Indicate presence of police killings
    is_city = 1  # Indicate it's a city
  ) %>%
  select(city_state, has_police_killing, is_city) %>%  # Select relevant columns
  rename(location = city_state)  # Rename for consistency

# Process county-level police killings data
county_police_killings <- police_killings_df %>%
  
  # Keep rows with non-missing County
  filter(!is.na(County)) %>%  
  mutate(
    
    # Convert date to Date type
    `Date of Incident (month/day/year)` = as.Date(`Date of Incident (month/day/year)`), 
    
    # Extract year
    year = year(`Date of Incident (month/day/year)`), 
    
    # Remove suffixes
    County = tolower(gsub(" County| Borough| Census Area| Municipality| Parish| city", "", County)),
    
    # Combine county and state
    county_state = paste(tolower(County), State, sep = "_") 
  ) %>%
  
  # Filter for years 2016-2020
  filter(year >= 2016 & year <= 2020) %>% 
  
  # Group by county_state
  group_by(county_state) %>%  
  
  # Count incidents
  dplyr::summarize(count = n(), .groups = 'drop') %>%
  mutate(
    
    # Indicate presence of police killings
    has_police_killing = ifelse(count > 0, 1, 0), 
    is_city = 0  # Indicate it's a county
  ) %>%
  
  # Select relevant columns
  select(county_state, has_police_killing, is_city) %>%  
  
  # Rename for consistency
  rename(location = county_state) 

# Combine city and county police killings data
police_killings <- bind_rows(county_police_killings, city_police_killings)

```


```{r get_funding_data}
load(file='data/funding/38651-0001-Data.rda') #2020
load(file="data/funding/37323-0001-Data.rda") #2016
load(file="data/funding/36164-0001-Data.rda") #2013
location_df <- read_csv("data/location_corrections.csv")
budgets_2021 <- read_csv("data/opbudgets_2021_2022.csv")

selected_2016 <- da37323.0001 %>%
  select(ORI9, OPBUDGET) %>%
  rename(budget_2016 = OPBUDGET)

selected_2013 <- da36164.0001 %>%
  select(ORI9, BDGT_TTL) %>%
  rename(budget_2013 = BDGT_TTL)

full_police_df <- da38651.0001 %>%
  left_join(selected_2016, by = "ORI9") %>%
  left_join(selected_2013, by = "ORI9")

police_df <- full_police_df %>%
  filter(AGENCYSAMPTYPE != "(5) State police") %>%
  select(-STATE) %>%
  mutate(
    AGENCYNAME = trimws(tolower(AGENCYNAME)),
  ) %>%
  bind_cols(location_df) %>%
  mutate(zip = as.character(zip)) %>%
  select(
    AGENCYNAME, location, OPBUDGET_2019, OPBUDGET, is_city, STATE,
    budget_2016, budget_2013, zip, where(~ all(!is.na(.)))
  ) %>%
  left_join(budgets_2021, by = c("AGENCYNAME", "STATE")) %>%
  select(-opbudget2019, -source)

```

```{r combine_dfs}
full_df <- police_df %>%
  left_join(blm, by = c("location", "is_city")) %>%
  left_join(demographics, by = c("location", "is_city")) %>%
  left_join(zips_pol_ideo_by_num, by = "zip") %>%
  left_join(police_killings, by = c("location")) %>%
  mutate(has_police_killing = ifelse(is.na(has_police_killing), 0, is.numeric(has_police_killing)),
         violent_protest = ifelse(is.na(violent_protest), 0, violent_protest),
         peaceful_protest = ifelse(is.na(peaceful_protest), 0, peaceful_protest))

budgets_full <- read_csv("budget_data_selected.csv")

df_cleaned <- full_df %>%
  distinct(AGENCYNAME, location, .keep_all = TRUE) %>%
  rename(OPBUDGET2020 = OPBUDGET) %>%
  select(-budget_2013, -budget_2016, -OPBUDGET_2019, -OPBUDGET2020, -opbudget_2021_2022) %>%
  bind_cols(budgets_full)

full_df_processed <- df_cleaned %>%
  select(-AGENCYNAME, -SUBMIT_DATE, -ORI9, -CITY, -STATE, -ZIP, 
         -City, -contains("OTH"), -location, -city, -is_city.y) %>% #remove cols that won't work with MissForest
  mutate(zip = as.numeric(zip),
         across(where(is.character), as.factor)) %>%
  rename(is_city = is_city.x)

save(full_df_processed, file = "before_imputation.RData")

```

```{r impute, eval = FALSE}
full_df_imputed <- missForest(full_df_processed, replace = TRUE)

OOB_error <- full_df_imputed$OOBerror #0.42

final_df <- full_df_imputed$ximp

full_df_processed <- as.data.frame(full_df_processed)

final_df_true <- cbind(df_cleaned$AGENCYNAME, df_cleaned$City, df_cleaned$STATE,
                      final_df)

final_df_true

save(final_df_true, file = "full_data.RData")
```

```{r imputation_line_chart, eval = FALSE}
# Initialize lists to store RMSE values
rmse_mice <- list()
rmse_missForest <- list()

# Number of iterations
num_iterations <- 5

# Running MICE and calculating RMSE between successive imputations
set.seed(123)
mice_imp <- mice(full_df_processed, m = num_iterations, method = 'rf', maxit = 50, seed = 123)
for (i in 2:num_iterations) {
  rmse_mice[[i-1]] <- calculate_rmse(complete(mice_imp, i-1), complete(mice_imp, i))
}

# Running missForest and calculating RMSE between successive imputations
set.seed(123)
imputed_missForest_list <- list()
for (i in 1:num_iterations) {
  imputed_missForest_list[[i]] <- missForest(full_df_processed)$ximp
  if (i > 1) {
    rmse_missForest[[i-1]] <- calculate_rmse(imputed_missForest_list[[i-1]], imputed_missForest_list[[i]])
  }
}

# Combine RMSE results into a data frame
rmse_df <- data.frame(
  Iteration = 1:(num_iterations-1),
  MICE = unlist(rmse_mice),
  missForest = unlist(rmse_missForest)
)

# Reshape the data frame for plotting
rmse_df_long <- rmse_df %>%
  pivot_longer(cols = c("MICE", "missForest"), names_to = "Method", values_to = "RMSE")

# Plot RMSE values
ggplot(rmse_df_long, aes(x = Iteration, y = RMSE, color = Method)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(title = "RMSE of Successive Imputations: MICE vs missForest",
       x = "Iteration",
       y = "RMSE")

# Calculate the mean range of the observed data
mean_range <- calculate_range(full_df_processed)

# Normalize RMSE values
normalized_rmse_mice <- sapply(rmse_mice, function(rmse) rmse / mean_range)
normalized_rmse_missForest <- sapply(rmse_missForest, function(rmse) rmse / mean_range)

# Combine normalized RMSE results into a data frame
normalized_rmse_df <- data.frame(
  Iteration = 1:(length(normalized_rmse_mice)),
  MICE = normalized_rmse_mice,
  missForest = normalized_rmse_missForest
)

# Reshape the data frame for plotting
normalized_rmse_df_long <- normalized_rmse_df %>%
  pivot_longer(cols = c("MICE", "missForest"), names_to = "Method", values_to = "Normalized_RMSE")

# Plot normalized RMSE values
figure1 <- ggplot(normalized_rmse_df_long, aes(x = Iteration, y = Normalized_RMSE, color = Method)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(x = "Iteration",
       y = "Normalized RMSE")

save(figure1, file = "figure1.rda")
```

```{r imputation_summary_stats, fig.height = 10, fig.width = 10, eval = FALSE}

# Load data (assuming "before_imputation.RData" has the required datasets)
load("before_imputation.RData")

columns_to_show <- c("OPBUDGET_2019", "OPBUDGET2020", "opbudget_2021_2022")
custom_labels <- c("OPBUDGET_2019" = "2019 Budget", "OPBUDGET2020" = "2020 Budget",
                   "opbudget_2021_2022" = "2021 Budget"
                   )

# Initialize list to store summary statistics
summary_stats <- list()

for (col_name in columns_to_show) {
  # Check if the column exists in the dataset and is numeric
  if (col_name %in% names(final_df_true) && col_name %in% names(full_df_processed) && is.numeric(final_df_true[[col_name]]) && is.numeric(full_df_processed[[col_name]])) {
    # Calculate and format summary statistics for the imputed and original data
    imputed_stats <- compute_summary_stats(final_df_true[[col_name]])
    original_stats <- compute_summary_stats(full_df_processed[[col_name]])
    
    # Get the custom label for the current column
    custom_label <- custom_labels[col_name]
    
    # Combine the statistics into a dataframe
    stats_df <- data.frame(
      Statistic = names(imputed_stats),
      Imputed = as.character(imputed_stats),
      Original = as.character(original_stats)
    )
    
    colnames(stats_df)[1] <- paste("Statistic:", custom_label)
    
    # Remove rows with NA values
    stats_df <- stats_df[complete.cases(stats_df), ]
    
    # Store the statistics dataframe in the list
    summary_stats[[col_name]] <- stats_df
  } else {
    warning(paste("Column", col_name, "is not numeric or does not exist in both datasets."))
  }
}

# Print the summary statistics (or use them as needed)
save(summary_stats, file = "summary_stats.rda")

```


```{r load_full_data}
load("full_data.RData")

```

## Pre-Match Analysis

```{r generate_pre_matched_tables}
# Generate tables
table1 <- create_result_table("peaceful_protest", final_df_true)
save(table1, file = "table1.rda")

table2 <- create_result_table("violent_protest", final_df_true)
save(table2, file = "table2.rda")

```

```{r normalize_data}
skewed_data <- final_df_true %>%
  select(mrp_ideology, percent_female, perc_age_0_17, 
         perc_age_18_34, perc_age_35_59, perc_age_60_74, perc_75_up,
         perc_black, perc_white, perc_hispanic, perc_less_hs,
         perc_associates, perc_bachelors, perc_graduate_professional,
         perc_not_in_labor_force, median_hh_income)

# Transform skewed data
normalized_data <- transform_skewed_data(skewed_data)

final_df_true <- as.data.frame(final_df_true)
normalized_data <- as.data.frame(normalized_data)

# Merge county_state column from full_protest_data with normalized_test
normalized_df <- cbind(agency_name = final_df_true$`df_cleaned$AGENCYNAME`, 
                       city = final_df_true$`df_cleaned$City`,
                       state = final_df_true$`df_cleaned$STATE`,
                       opbudget2013 = final_df_true$budget_2013,
                       opbudget2016 = final_df_true$budget_2016,
                       opbudget2019 = final_df_true$OPBUDGET_2019,
                       opbudget2020 = final_df_true$OPBUDGET2020,
                       opbudget2021 = final_df_true$opbudget_2021_2022,
                       is_city = final_df_true$is_city,
                       has_police_killing = final_df_true$has_police_killing,
                       violent_protest = final_df_true$violent_protest,
                       peaceful_protest = final_df_true$peaceful_protest,
                       normalized_data)

save(normalized_df, file = "normalized_data.RData")
  
```

```{r load_normalized_data}
load("normalized_data.RData")
```

```{r conduct_DID_pre_match}
table3 <- prepare_and_save_diff_in_diff(normalized_df, "peaceful_protest", "opbudget2019", "opbudget2021")
save(table3, file = "table3.rda")

table4 <- prepare_and_save_diff_in_diff(normalized_df, "violent_protest", "opbudget2019", "opbudget2021")
save(table4, file = "table4.rda")

```

## Matching

```{r create_p_scores, fig.height = 7, fig.width = 15}
peaceful_protests <- create_pscores(normalized_df, "peaceful_protest", "violent_protest")

plot_peaceful_protests <- ggplot(peaceful_protests) + 
  aes(x = p_score, fill = factor(peaceful_protest), color = factor(peaceful_protest)) + 
  geom_density(alpha = 0.5) +
  xlab("P-Score") +
  ylab("Density") +
  labs(fill = "peaceful_protest", color = "peaceful_protest",
       title = "Propensity Scores: Peaceful Protest: County Demographics") + 
  theme_minimal()

violent_protests <- create_pscores(normalized_df, "violent_protest", "peaceful_protest")

plot_violent_protests <- ggplot(violent_protests) + 
  aes(x = p_score, fill = factor(violent_protest), color = factor(violent_protest)) + 
  geom_density(alpha = 0.5) +
  xlab("P-Score") +
  ylab("Density") +
  labs(fill = "violent_protest", color = "violent_protest",
       title = "Propensity Scores: Violent Protest: County Demographics") + 
  theme_minimal()

```

```{r conduct_match_it, echo = TRUE}
m_out_peaceful <- MatchIt::matchit(peaceful_protest~p_score, 
                          data = peaceful_protests,
                          method = "genetic",
                          ratio = 1,
                          replace = F,
                          distance = "mahalanobis")

m_out_violent <- MatchIt::matchit(violent_protest~p_score, 
                          data = violent_protests,
                          method = "genetic",
                          ratio = 2,
                          replace = F,
                          distance = "mahalanobis")

```

```{r output_matchit_results}
m_data_peaceful <- MatchIt::match.data(m_out_peaceful)
m_data_violent <- MatchIt::match.data(m_out_violent)

counts <- table(m_data_peaceful$peaceful_protest)
num_control <- counts[as.character(0)]  # Number of control units
num_treatment <- counts[as.character(1)]

cat("The peaceful matched data set has", dim(m_data_peaceful)[1], "counties.", num_control, "are in control",
    num_treatment, "are in treatment.", "The original dataset had", nrow(normalized_df), "counties. \n\n")

counts <- table(m_data_violent$violent_protest)
num_control <- counts[as.character(0)]  # Number of control units
num_treatment <- counts[as.character(1)]

cat("The violent matched data set has", dim(m_data_violent)[1], "counties.", num_control, "are in control",
    num_treatment, "are in treatment.", "The original dataset had", nrow(normalized_df), "counties.")

```

```{r removed_rows}
original_rows_peaceful <- rownames(peaceful_protests)
original_rows_violent <- rownames(violent_protests)

matched_rows_peaceful <- rownames(m_data_peaceful)
matched_rows_violent <- rownames(m_data_violent)

# Find the rows that were removed during matching
removed_rows_peaceful <- setdiff(original_rows_peaceful, matched_rows_peaceful)
removed_rows_violent <- setdiff(original_rows_violent, matched_rows_violent)

removed_data_peaceful <- peaceful_protests[removed_rows_peaceful, ]
removed_data_violent <- violent_protests[removed_rows_violent, ]

```

```{r plot_removed_rows}
# Process and plot for peaceful protests
figure2 <- process_and_plot(
  df = normalized_df,
  removed_rows = removed_rows_peaceful,
  remove_col = "peaceful_protest",
  plot_title = "Propensity Scores: Peaceful Protest",
  output_file = "figure1.rda"
)

# Process and plot for violent protests
figure3 <- process_and_plot(
  df = normalized_df,
  removed_rows = removed_rows_violent,
  remove_col = "violent_protest",
  plot_title = "Propensity Scores: Violent Protest",
  output_file = "figure2.rda"
)

save(figure2, file = "figure2.rda")
save(figure3, file = "figure3.rda")
```

```{r generate_post_matched_tables}
table5 <- create_result_table("peaceful_protest", m_data_peaceful)
save(table5, file = "table5.rda")

table6 <- create_result_table("violent_protest", m_data_violent)
save(table6, file = "table6.rda")
```

```{r conduct_DID_post_match}
table7 <- prepare_and_save_diff_in_diff(m_data_peaceful, "peaceful_protest", 
                              "opbudget2019", "opbudget2021")
save(table7, file = "table7.rda")

table8 <- prepare_and_save_diff_in_diff(m_data_violent, "violent_protest", 
                              "opbudget2019", "opbudget2021")
save(table8, file = "table8.rda")

```

# Parallel Trends

```{r run_trends}
parallel_peaceful <- run_parallel_trends(data = m_data_peaceful, protest_var = "peaceful_protest")
save(parallel_peaceful, file = "parallel_peaceful.rda")

# For violent protests
parallel_violent <- run_parallel_trends(data = m_data_violent, protest_var = "violent_protest")
save(parallel_violent, file = "parallel_violent.rda")
```
